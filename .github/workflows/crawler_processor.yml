name: Process crawler

on:
  workflow_dispatch:

jobs:
  build:
    name: Process crawler
    permissions:
      actions: write
      checks: write
      contents: write
      deployments: write
      issues: write
      packages: write
      pull-requests: write
      repository-projects: write
      security-events: write
      statuses: write
    runs-on: ubuntu-latest
    env:
      SUPABASE_URL: ${{secrets.SUPABASE_URL}}
      SUPABASE_ANON_KEY: ${{secrets.SUPABASE_ANON_KEY}}
      SUPABASE_SERVICE_KEY: ${{secrets.SUPABASE_SERVICE_KEY}}
    steps:
    - name: Extract branch name
      shell: bash
      run: echo "branch=$(echo ${GITHUB_REF#refs/heads/})" >> $GITHUB_OUTPUT
      id: extract_branch
    - uses: actions/checkout@v3
      with:
          persist-credentials: false
          fetch-depth: 0
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9.13'
    - name: Install dependencies
      run: |
        python3 -m pip install --upgrade pip
        pip install pandas==1.2.0 numpy==1.19.5 BeautifulSoup4==4.9.3 requests==2.28.1 urllib3==1.26.12 typer==0.6.1 python-decouple==3.6 pytest==7.1.3 supabase==0.7.1
        pip install get-chrome-driver --upgrade
        pip install -r requirements.txt
    - name: Build data
      run: |
        python3 crawler.py
    - name: Commit files
      run: |
        git config --local user.email "ube@coder.okinawa.jp"
        git config --local user.name "Tomoyuki UBE"
        git add data
        git diff-index --quiet HEAD || git commit -m "[BOT] crawler"
    - name: Push changes
      uses: ad-m/github-push-action@master
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        branch: ${{ steps.extract_branch.outputs.branch }}
